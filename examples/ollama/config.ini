[OpenAI]
# Using Ollama as the API type
# Ollama is a local LLM serving tool that allows you to run models on your own hardware.
API_TYPE=ollama
BASE_URL=http://localhost:11434/v1


# Ollama models must be tweaked to accept larger input prompts, otherwise they'll truncate the input.
MODEL=gemma3:1b-32k
#gemma3:1b-32k
#gemma3:4b-32k

# num_ctx is a special Ollama parameter that should be used to set the maximum input size, however
# it is being ignored on our tests so far.
#
#NUM_CTX=32768

TEMPERATURE=1.0
FREQ_PENALTY=0.1
PRESENCE_PENALTY=0.1
MAX_TOKENS=8192

[Logging]
LOGLEVEL=DEBUG
# ERROR
# WARNING
# INFO
# DEBUG